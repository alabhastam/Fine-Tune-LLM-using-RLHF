{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:38:29.350610Z","iopub.execute_input":"2025-10-17T20:38:29.351188Z","iopub.status.idle":"2025-10-17T20:38:34.369137Z","shell.execute_reply.started":"2025-10-17T20:38:29.351132Z","shell.execute_reply":"2025-10-17T20:38:34.367459Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Load Model and Tokenizer\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\n# The model we want to fine-tune\nmodel_name = \"EleutherAI/gpt-neo-125m\"\n\n# Configuration for 4-bit quantization\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",       # Use \"nf4\" for better precision\n    bnb_4bit_compute_dtype=torch.float16, # Use float16 for computation\n)\n\n# Load the model with the specified quantization configuration\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    trust_remote_code=True # Required for some models\n)\n# Disable cache for training with PEFT\nmodel.config.use_cache = False\n\n# Load the tokenizer for the model\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n# Set the padding token to be the same as the end-of-sequence token\ntokenizer.pad_token = tokenizer.eos_token\n\nprint(\"Model and Tokenizer loaded successfully!\")\nprint(model) # This will show you the model architecture with the quantization layers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:38:40.343694Z","iopub.execute_input":"2025-10-17T20:38:40.344074Z","iopub.status.idle":"2025-10-17T20:39:35.696472Z","shell.execute_reply.started":"2025-10-17T20:38:40.344043Z","shell.execute_reply":"2025-10-17T20:39:35.695091Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b640c9175324a08a611e1778d7cb403"}},"metadata":{}},{"name":"stderr","text":"2025-10-17 20:38:53.499478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760733533.781465     140 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760733533.859990     140 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"773429a743644415bc6edd8551f851e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a8a2a63b53e4c838647ab57df39f623"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a927531aecf44e47ab14cd42117f88cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f796ee4f58af4959b1e8ba625f5b7c58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee45d0a3a2b14486a32fe49ac0d07499"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68520802b5e14b22a70b50c5ed6a22f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f19c7a1879bf4428b602ffea9df7a2eb"}},"metadata":{}},{"name":"stdout","text":"Model and Tokenizer loaded successfully!\nGPTNeoForCausalLM(\n  (transformer): GPTNeoModel(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(2048, 768)\n    (drop): Dropout(p=0.0, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPTNeoBlock(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTNeoAttention(\n          (attention): GPTNeoSelfAttention(\n            (attn_dropout): Dropout(p=0.0, inplace=False)\n            (resid_dropout): Dropout(p=0.0, inplace=False)\n            (k_proj): Linear4bit(in_features=768, out_features=768, bias=False)\n            (v_proj): Linear4bit(in_features=768, out_features=768, bias=False)\n            (q_proj): Linear4bit(in_features=768, out_features=768, bias=False)\n            (out_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n          )\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPTNeoMLP(\n          (c_fc): Linear4bit(in_features=768, out_features=3072, bias=True)\n          (c_proj): Linear4bit(in_features=3072, out_features=768, bias=True)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)\n","output_type":"stream"}],"execution_count":2}]}